{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: Final Prediction Computation\n",
    "\n",
    "This notebook generates the final model predictions and formats them for submission on Codabench. \n",
    "\n",
    "The evaluation dataset comprises data from 39 stations included in the training set and 13 stations exclusive to the evaluation set.\n",
    "\n",
    "<img src=\"../images/notebook-4.png\" alt=\"Experiment Diagram\" style=\"width:75%;\" style=\"text-align:center;\" />\n",
    "\n",
    "\n",
    "### 1. Imports\n",
    "Starts by importing the necessary libraries, configuring environment paths, and loading custom utility functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import joblib\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..','..','..')))\n",
    "\n",
    "from src.utils.model import load_models_auto\n",
    "from src.utils.analysis import create_predict_function, create_quantile_function\n",
    "from src.utils.model import load_models_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.125\n",
    "NUMBER_OF_WEEK = 4\n",
    "USE_AUTO_SCAN = True  # Toggle this to switch between the loading of the last model of the manual load of a specific model\n",
    "FINAL_MODEL = \"qrf\"\n",
    "\n",
    "\n",
    "#replace with your directory\n",
    "\n",
    "MODEL_DIR = \"/N/lustre/project/proj-212/Ramtelpp/PersonalProject/Coda/model/\"\n",
    "EVAL_DIR = \"/N/lustre/project/proj-212/Ramtelpp/PersonalProject/Coda/data/evaluation/\"\n",
    "EVAL_DIR_MINI = \"/N/lustre/project/proj-212/Ramtelpp/PersonalProject/Coda/data/evaluation_mini/\"\n",
    "COMPUTE_MINICHALLENGE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data and models Loading\n",
    "\n",
    "Loading of the inference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "inference_data = pd.read_csv(f\"{EVAL_DIR}dataset_baseline.csv\")\n",
    "inference_data = inference_data.set_index(\"ObsDate\")\n",
    "\n",
    "if COMPUTE_MINICHALLENGE:\n",
    "    inference_data_mini = pd.read_csv(f\"{EVAL_DIR_MINI}dataset_baseline.csv\")\n",
    "    inference_data_mini = inference_data_mini.set_index(\"ObsDate\")\n",
    "    inference_data = pd.concat([inference_data, inference_data_mini], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{EVAL_DIR}dataset_baseline.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['station_code',\n",
    "    \"water_flow_lag_1w\",\n",
    "    \"water_flow_lag_2w\",\n",
    "    \"soil_moisture_region\",\n",
    "    \"precipitation_region_lag_1w\",\n",
    "    \"catchment\",\n",
    "    \"soil_moisture\",\n",
    "    \"temperatures\",\n",
    "    \"precipitation_sector_lag_1w\",\n",
    "    \"soil_moisture_sub_sector\",\n",
    "    \"precipitation_sub_sector_lag_1w\",\n",
    "    \"precipitation_zone\",\n",
    "    \"precipitation_sub_sector\",\n",
    "    \"evaporation_sub_sector_lag_1w\",\n",
    "    \"temperature_region\"\n",
    "]\n",
    "\n",
    "inference_data =  inference_data[feature_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models based on conditions\n",
    "final_models = []\n",
    "\n",
    "if FINAL_MODEL == \"qrf\":\n",
    "\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"qrf_quantile\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-04-11_20-24-55_week_0.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-04-11_20-24-55_week_1.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-04-11_20-24-55_week_2.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-04-11_20-24-55_week_3.pkl\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predictions computation\n",
    "\n",
    "Evaluation data include a spatio-temporal split and a temporal only split.\n",
    "\n",
    "<img src=\"../images/eval.png\" alt=\"Experiment Diagram\" style=\"width:50%;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = inference_data[['station_code']].copy()\n",
    "y_pred_test_quantile = {}\n",
    "y_pred_test = {}\n",
    "X_test = inference_data.drop(columns=['station_code'])\n",
    "X_test = X_test.drop(columns=['altitude (m)', 'catchment_area (km2)'], errors='ignore')\n",
    "for i in range(NUMBER_OF_WEEK):\n",
    "    \n",
    "    if FINAL_MODEL == \"qrf\":\n",
    "        predict_adjusted = create_predict_function(final_models, i, FINAL_MODEL)\n",
    "        quantile_adjusted = create_quantile_function(final_models, i, FINAL_MODEL, ALPHA)\n",
    "    \n",
    "        y_pred_test[i] = predict_adjusted(X_test)\n",
    "        y_pred_test_quantile[i] = quantile_adjusted(X_test)\n",
    "\n",
    "for i in range(NUMBER_OF_WEEK):\n",
    "    predictions[f\"week_{i}_pred\"] = y_pred_test[i]\n",
    "    predictions[f\"week_{i}_sup\"] = y_pred_test_quantile[i][:,1]\n",
    "    predictions[f\"week_{i}_inf\"] = y_pred_test_quantile[i][:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Saving of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to a csv file\n",
    "predictions[\"ObsDate\"] = X_test.index\n",
    "predictions.to_csv(f\"{EVAL_DIR}predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ZIP file containing predictions.csv\n",
    "with zipfile.ZipFile(f\"{EVAL_DIR}predictions.zip\", 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write(f\"{EVAL_DIR}predictions.csv\", \"predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
