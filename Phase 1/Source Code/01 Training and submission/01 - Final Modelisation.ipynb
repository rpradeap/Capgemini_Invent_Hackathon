{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from mapie.regression import MapieQuantileRegressor\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..')))\n",
    "from src.utils.model import split_dataset, compare_models_per_station, create_deep_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with your directory\n",
    "\n",
    "INPUT_DIR = \"/N/lustre/project/proj-212/Ramtelpp/PersonalProject/Coda/data/input/\"\n",
    "MODEL_DIR = \"/N/lustre/project/proj-212/Ramtelpp/PersonalProject/Coda/model/\"\n",
    "DATASET_DIR = \"/N/lustre/project/proj-212/Ramtelpp/PersonalProject/Coda/data/\"\n",
    "\n",
    "SEED = 42\n",
    "NUMBER_OF_WEEK = 4 # Number of weeks to predict one model is trained per week\n",
    "\n",
    "FINAL_MODELS = [\"qrf\",]\n",
    "\n",
    "qrf = {}\n",
    "COLUMNS_TO_DROP = [\"water_flow_week1\", \"water_flow_week2\", \"water_flow_week3\", \"water_flow_week4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Loading\n",
    "Load in the baseline datasets, create the directory to save models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_train = pd.read_csv(f\"dataset_baseline.csv\") # the database is Preprocessing\n",
    "dataset_train = dataset_train.set_index(\"ObsDate\")\n",
    "if not os.path.exists(f\"{MODEL_DIR}final/\"):\n",
    "    os.makedirs(f\"{MODEL_DIR}final/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing removal of unnecessary columns, setup of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset_train.drop(columns=COLUMNS_TO_DROP)\n",
    "y_train = {}\n",
    "\n",
    "for i in range(0, NUMBER_OF_WEEK):\n",
    "    y_train[i] = dataset_train[f\"water_flow_week{i+1}\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Development (QRF)\n",
    "\n",
    "- **Training:**  \n",
    "  Initializes a `RandomForestQuantileRegressor` with the following parameters:\n",
    "  - 100 estimators\n",
    "  - Maximum depth of 10\n",
    "  - Minimum of 10 samples per leaf\n",
    "\n",
    "  These parameters allow for relatively fast training, though they are not optimized for peak performance. \n",
    "  \n",
    "  The model is then fitted using `X_train` and the corresponding weekly target `y_train[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_qrf = X_train.drop(columns=[\"station_code\"])\n",
    "SEED = 42  \n",
    "random_state = SEED\n",
    "\n",
    "# Drop the 'station_code' column\n",
    "X_train_qrf = X_train.drop(columns=[\"station_code\"])\n",
    "\n",
    "# Optimal features selected \n",
    "feature = [\n",
    "    \"water_flow_lag_1w\",\n",
    "    \"water_flow_lag_2w\",\n",
    "    \"soil_moisture_region\",\n",
    "    \"precipitation_region_lag_1w\",\n",
    "    \"catchment\",\n",
    "    \"soil_moisture\",\n",
    "    \"temperatures\",\n",
    "    \"precipitation_sector_lag_1w\",\n",
    "    \"soil_moisture_sub_sector\",\n",
    "    \"precipitation_sub_sector_lag_1w\",\n",
    "    \"precipitation_zone\",\n",
    "    \"precipitation_sub_sector\",\n",
    "    \"evaporation_sub_sector_lag_1w\",\n",
    "    \"temperature_region\"\n",
    "]  # selected features\n",
    "\n",
    "X_train_qrf = X_train_qrf[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#range(NUMBER_OF_WEEK)\n",
    "\n",
    "if \"qrf\" in FINAL_MODELS:\n",
    "    for i in range(NUMBER_OF_WEEK):\n",
    "        print(f\"Training week {i}\")\n",
    "        # Train RandomForestQuantileRegressor\n",
    "        qrf[i] = RandomForestQuantileRegressor(n_estimators=1000, max_depth=25, min_samples_leaf=25, random_state=random_state)\n",
    "        qrf[i].fit(X_train_qrf, y_train[i])\n",
    "        time = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        model_path = f\"{MODEL_DIR}final/qrf_quantile_{time}_week_{i}.pkl\"\n",
    "        joblib.dump(qrf[i], model_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
